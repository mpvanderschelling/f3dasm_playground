{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 12:27:12.260803: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-21 12:27:12.479957: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-21 12:27:13.521916: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.1/lib64:/usr/local/cuda-11.1/lib64\n",
      "2022-12-21 12:27:13.522064: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.1/lib64:/usr/local/cuda-11.1/lib64\n",
      "2022-12-21 12:27:13.522079: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from mlclasses_f3dasm import LinearRegression, MLArchitecture, get_reshaped_array_from_list_of_arrays, get_flat_array_from_list_of_arrays\n",
    "import tensorflow as tf\n",
    "import f3dasm\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from copy import copy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import tensorflow as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule:\n",
    "    \"\"\"Defined in :numref:`subsec_oo-design-models`\"\"\"\n",
    "    def __init__(self, root='../data'):\n",
    "        self.root= root\n",
    "\n",
    "    def get_dataloader(self, train):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.get_dataloader(train=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.get_dataloader(train=False)\n",
    "\n",
    "    def get_tensorloader(self, tensors, train, indices=slice(0, None)):\n",
    "        \"\"\"Defined in :numref:`sec_synthetic-regression-data`\"\"\"\n",
    "        tensors = tuple(a[indices] for a in tensors)\n",
    "        shuffle_buffer = tensors[0].shape[0] if train else 1\n",
    "        return tf.data.Dataset.from_tensor_slices(tensors).shuffle(\n",
    "            buffer_size=shuffle_buffer).batch(self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 12:27:25.451751: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-12-21 12:27:25.451852: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (martin): /proc/driver/nvidia/version does not exist\n",
      "2022-12-21 12:27:25.453667: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "num_train = 1000\n",
    "num_val = 1000\n",
    "n = num_train + num_val\n",
    "b = 4.2\n",
    "noise_multiplier = 0.01\n",
    "w = tf.constant([2, -3.4])\n",
    "noise = tf.random.normal((n, 1)) * noise_multiplier\n",
    "\n",
    "X = tf.random.normal((n, w.shape[0])) # (num, dim)\n",
    "y = tf.matmul(X, tf.reshape(w, (-1, 1))) + b + noise # (1, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1001 // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = tf.constant([0. , 1.])\n",
    "len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regression_data(n: int, b: float, w: List[float], noise_multiplier: float = 0.01) -> f3dasm.Data:\n",
    "    w = tf.constant(w)\n",
    "    dim = len(w)\n",
    "    num_train = n // 2\n",
    "    num_val = n - num_train\n",
    "\n",
    "    noise = tf.random.normal((n, 1)) * noise_multiplier\n",
    "\n",
    "    X = tf.random.normal((n, w.shape[0])) # (num, dim)\n",
    "    y = tf.matmul(X, tf.reshape(w, (-1, 1))) + b + noise # (1, dim)\n",
    "\n",
    "    # Create designspace\n",
    "    design = f3dasm.make_nd_continuous_design(bounds=np.tile([-np.inf,np.inf], (dim, 1)), dimensionality=dim)\n",
    "\n",
    "    # Create Data object\n",
    "    regression_data = f3dasm.Data(design)\n",
    "\n",
    "    regression_data.add_numpy_arrays(input=X.numpy(), output=y.numpy())\n",
    "    return regression_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.232323</td>\n",
       "      <td>1.372074</td>\n",
       "      <td>0.239957</td>\n",
       "      <td>-0.152301</td>\n",
       "      <td>-0.373612</td>\n",
       "      <td>1.439567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.270130</td>\n",
       "      <td>-0.729988</td>\n",
       "      <td>0.677494</td>\n",
       "      <td>0.310054</td>\n",
       "      <td>-3.026062</td>\n",
       "      <td>21.920729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.653078</td>\n",
       "      <td>-0.652458</td>\n",
       "      <td>-1.817044</td>\n",
       "      <td>0.496654</td>\n",
       "      <td>-0.959227</td>\n",
       "      <td>0.606139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.797568</td>\n",
       "      <td>-0.295403</td>\n",
       "      <td>-0.213270</td>\n",
       "      <td>-0.704185</td>\n",
       "      <td>-0.032756</td>\n",
       "      <td>1.123363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.062434</td>\n",
       "      <td>-0.363580</td>\n",
       "      <td>-1.267274</td>\n",
       "      <td>-1.586046</td>\n",
       "      <td>0.017212</td>\n",
       "      <td>-9.461775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-0.465056</td>\n",
       "      <td>-0.326835</td>\n",
       "      <td>1.198465</td>\n",
       "      <td>-1.215369</td>\n",
       "      <td>0.895153</td>\n",
       "      <td>-0.813348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-0.022622</td>\n",
       "      <td>-2.979682</td>\n",
       "      <td>1.005019</td>\n",
       "      <td>-0.926413</td>\n",
       "      <td>0.347308</td>\n",
       "      <td>11.925545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-1.001367</td>\n",
       "      <td>-0.821210</td>\n",
       "      <td>-0.917331</td>\n",
       "      <td>-0.062754</td>\n",
       "      <td>0.305457</td>\n",
       "      <td>-1.046961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-0.694200</td>\n",
       "      <td>-2.073502</td>\n",
       "      <td>0.880892</td>\n",
       "      <td>-0.912830</td>\n",
       "      <td>-0.003548</td>\n",
       "      <td>8.165611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-1.032161</td>\n",
       "      <td>1.047530</td>\n",
       "      <td>1.636716</td>\n",
       "      <td>0.802599</td>\n",
       "      <td>1.004212</td>\n",
       "      <td>8.718799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         input                                             output\n",
       "            x0        x1        x2        x3        x4          y\n",
       "0     0.232323  1.372074  0.239957 -0.152301 -0.373612   1.439567\n",
       "1    -0.270130 -0.729988  0.677494  0.310054 -3.026062  21.920729\n",
       "2    -1.653078 -0.652458 -1.817044  0.496654 -0.959227   0.606139\n",
       "3     0.797568 -0.295403 -0.213270 -0.704185 -0.032756   1.123363\n",
       "4     1.062434 -0.363580 -1.267274 -1.586046  0.017212  -9.461775\n",
       "...        ...       ...       ...       ...       ...        ...\n",
       "1995 -0.465056 -0.326835  1.198465 -1.215369  0.895153  -0.813348\n",
       "1996 -0.022622 -2.979682  1.005019 -0.926413  0.347308  11.925545\n",
       "1997 -1.001367 -0.821210 -0.917331 -0.062754  0.305457  -1.046961\n",
       "1998 -0.694200 -2.073502  0.880892 -0.912830 -0.003548   8.165611\n",
       "1999 -1.032161  1.047530  1.636716  0.802599  1.004212   8.718799\n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_data = create_regression_data(n=2000, b=4.2, w=[2, -3.4, 5., 6.7, -3.4])\n",
    "reg_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>-0.460329</td>\n",
       "      <td>-2.022260</td>\n",
       "      <td>-0.385206</td>\n",
       "      <td>-0.756874</td>\n",
       "      <td>-1.213675</td>\n",
       "      <td>7.287460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>-1.172031</td>\n",
       "      <td>-0.561345</td>\n",
       "      <td>2.406005</td>\n",
       "      <td>-1.833227</td>\n",
       "      <td>0.610663</td>\n",
       "      <td>1.428991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.910888</td>\n",
       "      <td>-0.819529</td>\n",
       "      <td>-0.884486</td>\n",
       "      <td>-0.374983</td>\n",
       "      <td>-0.303449</td>\n",
       "      <td>2.897491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.128376</td>\n",
       "      <td>1.273280</td>\n",
       "      <td>-0.487071</td>\n",
       "      <td>0.157668</td>\n",
       "      <td>0.470714</td>\n",
       "      <td>-2.854374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>-0.440045</td>\n",
       "      <td>0.356057</td>\n",
       "      <td>-0.354154</td>\n",
       "      <td>0.340894</td>\n",
       "      <td>-0.906325</td>\n",
       "      <td>5.713332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>-0.584667</td>\n",
       "      <td>0.833516</td>\n",
       "      <td>-1.151453</td>\n",
       "      <td>0.734843</td>\n",
       "      <td>0.573349</td>\n",
       "      <td>-2.602968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.609697</td>\n",
       "      <td>1.524423</td>\n",
       "      <td>1.152034</td>\n",
       "      <td>0.195733</td>\n",
       "      <td>-0.133834</td>\n",
       "      <td>7.758787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>2.200780</td>\n",
       "      <td>0.421673</td>\n",
       "      <td>-1.870648</td>\n",
       "      <td>0.146652</td>\n",
       "      <td>-0.682617</td>\n",
       "      <td>1.116112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>-0.226725</td>\n",
       "      <td>-1.051592</td>\n",
       "      <td>0.505996</td>\n",
       "      <td>-0.064839</td>\n",
       "      <td>-1.579572</td>\n",
       "      <td>14.801998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1.363118</td>\n",
       "      <td>0.508119</td>\n",
       "      <td>0.710688</td>\n",
       "      <td>1.283337</td>\n",
       "      <td>-0.607225</td>\n",
       "      <td>19.425373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         input                                             output\n",
       "            x0        x1        x2        x3        x4          y\n",
       "1709 -0.460329 -2.022260 -0.385206 -0.756874 -1.213675   7.287460\n",
       "689  -1.172031 -0.561345  2.406005 -1.833227  0.610663   1.428991\n",
       "22    0.910888 -0.819529 -0.884486 -0.374983 -0.303449   2.897491\n",
       "234   0.128376  1.273280 -0.487071  0.157668  0.470714  -2.854374\n",
       "579  -0.440045  0.356057 -0.354154  0.340894 -0.906325   5.713332\n",
       "...        ...       ...       ...       ...       ...        ...\n",
       "1676 -0.584667  0.833516 -1.151453  0.734843  0.573349  -2.602968\n",
       "129   0.609697  1.524423  1.152034  0.195733 -0.133834   7.758787\n",
       "900   2.200780  0.421673 -1.870648  0.146652 -0.682617   1.116112\n",
       "826  -0.226725 -1.051592  0.505996 -0.064839 -1.579572  14.801998\n",
       "1600  1.363118  0.508119  0.710688  1.283337 -0.607225  19.425373\n",
       "\n",
       "[1600 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = reg_data.split_to_train_test(test_size=0.2)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[         input                                             output\n",
       "             x0        x1        x2        x3        x4          y\n",
       " 1709 -0.460329 -2.022260 -0.385206 -0.756874 -1.213675   7.287460\n",
       " 689  -1.172031 -0.561345  2.406005 -1.833227  0.610663   1.428991\n",
       " 22    0.910888 -0.819529 -0.884486 -0.374983 -0.303449   2.897491\n",
       " 234   0.128376  1.273280 -0.487071  0.157668  0.470714  -2.854374\n",
       " 579  -0.440045  0.356057 -0.354154  0.340894 -0.906325   5.713332\n",
       " ...        ...       ...       ...       ...       ...        ...\n",
       " 1030  0.332746 -0.841317 -0.353050 -0.359378  0.474521   1.928897\n",
       " 1098  0.654703  1.688435 -0.187183  0.736782 -1.366534   8.422804\n",
       " 1874  0.640359  0.486049 -0.541170 -0.940912  0.000187  -5.179186\n",
       " 1967 -1.550178  0.377595  0.966798  0.497803 -0.264029   8.882068\n",
       " 1317  0.321732 -1.817388  0.696517 -0.937991 -0.851060  11.123124\n",
       " \n",
       " [229 rows x 6 columns],\n",
       "          input                                             output\n",
       "             x0        x1        x2        x3        x4          y\n",
       " 1248  0.892895 -0.875911  1.368784 -0.158562  0.011326  14.731617\n",
       " 421   1.377683  0.838408  1.457909  0.076293 -0.247535  12.731087\n",
       " 82   -0.576811 -1.009450  0.062117 -0.911401  1.826479  -5.520737\n",
       " 15   -0.024907  0.785125 -0.753010  0.834156  0.554362   1.427498\n",
       " 145   0.968994  0.494110  0.492083  0.599145 -1.314131  15.396049\n",
       " ...        ...       ...       ...       ...       ...        ...\n",
       " 427  -0.503010 -0.066830 -1.889803 -0.578386  1.059499 -13.520705\n",
       " 616   0.123563  0.107315  1.179733  0.245910 -0.067232  11.870162\n",
       " 1816  0.346796  0.148780  0.150387 -0.169649  0.352507   2.819372\n",
       " 353   0.286793  0.393497  0.789152  0.361449 -0.871745  12.763337\n",
       " 725   0.353738  2.310795  1.227614  0.624126 -0.659120   9.594915\n",
       " \n",
       " [229 rows x 6 columns],\n",
       "          input                                             output\n",
       "             x0        x1        x2        x3        x4          y\n",
       " 1066  1.267381 -0.063127 -0.335799 -1.978071  0.064323  -8.205115\n",
       " 849  -0.233536  0.548825  0.103564 -0.236200  0.812051  -1.959464\n",
       " 1941  1.141747 -0.515361  1.086521 -0.978700 -1.598187  12.544931\n",
       " 112  -1.377982  0.031386 -2.081969  1.425790 -0.786532   3.158446\n",
       " 954  -0.194151 -0.689089 -0.158706 -0.083785  0.192617   4.137661\n",
       " ...        ...       ...       ...       ...       ...        ...\n",
       " 449   0.100201  0.496715 -0.333613  0.537295 -0.812072   7.402890\n",
       " 1121 -0.582592  0.429492  0.388774  0.117043  1.435048  -0.579387\n",
       " 1036  0.152587  1.559933 -0.386630  2.092660 -0.849382  14.154606\n",
       " 1145 -0.429083  1.353834  1.567193 -0.169324 -0.272916   6.374466\n",
       " 1678  1.956149  1.284337 -0.633953  1.546784  0.260119  10.057681\n",
       " \n",
       " [229 rows x 6 columns],\n",
       "          input                                             output\n",
       "             x0        x1        x2        x3        x4          y\n",
       " 66   -0.811356  0.290706 -1.375219  0.294507  1.188901  -7.336782\n",
       " 126   0.096201  1.384642 -0.141457  0.666330  0.051961   3.254466\n",
       " 1311  1.180948 -0.118574  1.186952  0.114021 -1.190797  17.729067\n",
       " 685   0.493833  0.126169 -0.892552 -0.494179 -0.516504  -1.254158\n",
       " 1378 -2.074758  2.049193 -0.358389 -1.249951  0.175972 -17.671379\n",
       " ...        ...       ...       ...       ...       ...        ...\n",
       " 643   0.599117 -2.074380 -1.483002  1.161159  0.032215  12.712916\n",
       " 1033 -0.057648 -1.912511  0.390827  0.362368 -1.092318  18.670935\n",
       " 2    -1.653078 -0.652458 -1.817044  0.496654 -0.959227   0.606139\n",
       " 598  -0.392407  1.255568 -0.360817  0.158611  0.063286  -1.794060\n",
       " 1834 -1.244434 -1.002989 -0.491801  0.065596 -0.736480   5.599540\n",
       " \n",
       " [229 rows x 6 columns],\n",
       "          input                                             output\n",
       "             x0        x1        x2        x3        x4          y\n",
       " 1266 -1.185382 -1.088349  0.109063  0.468490  0.018538   9.134448\n",
       " 684  -0.400811  0.078511 -1.524007  0.548602  0.681950  -3.133330\n",
       " 568   0.864777 -0.609674 -0.189215 -1.113711  0.291779  -1.408630\n",
       " 486  -0.388030 -0.242234  1.942458 -1.292639 -0.334576   6.434533\n",
       " 1167  0.352672  0.195080  0.327839 -0.583776 -0.755003   4.537579\n",
       " ...        ...       ...       ...       ...       ...        ...\n",
       " 1052  0.394514  1.483482 -0.575786 -0.122727 -1.284397   0.618867\n",
       " 984  -2.683420  1.816341 -0.906935 -0.137971  0.885041 -15.811172\n",
       " 463   1.644027 -0.361372  0.916261  1.406471 -0.551899  24.605011\n",
       " 1462 -0.124708  1.201834  0.280885  0.486716  0.376087   3.235421\n",
       " 1633  0.025789  1.426845 -1.364176 -0.716893 -1.264794  -7.911910\n",
       " \n",
       " [228 rows x 6 columns],\n",
       "          input                                             output\n",
       "             x0        x1        x2        x3        x4          y\n",
       " 767  -0.650697 -0.499503  0.109163  0.326748  0.741776   4.796001\n",
       " 1263 -0.737693 -1.001231  1.340329  0.038818  1.703109   7.276098\n",
       " 766  -1.028385 -0.780643  0.353494  0.269848 -1.255318  12.635544\n",
       " 1493 -0.179914  1.771887 -0.561192 -0.154127  0.155555  -6.538978\n",
       " 837   1.141509  0.146005 -1.215303  1.154498  0.401126   6.276591\n",
       " ...        ...       ...       ...       ...       ...        ...\n",
       " 1157  0.506729  1.378855  1.660250 -1.225897  1.422295  -4.227728\n",
       " 1344 -2.617661  0.369421  0.411119 -0.238873  0.226593  -2.594572\n",
       " 1190 -0.678403  0.074335 -0.750386 -0.170298 -1.894579   4.140033\n",
       " 626   0.969598 -2.201342 -0.252569 -0.050765 -0.802120  14.749918\n",
       " 507  -0.272615 -0.250219  0.640087 -0.282273 -1.496919  10.909925\n",
       " \n",
       " [228 rows x 6 columns],\n",
       "          input                                             output\n",
       "             x0        x1        x2        x3        x4          y\n",
       " 1835  0.668146 -1.881045  0.121575  0.953672  0.658515  16.689930\n",
       " 890   1.791495  0.012037  1.306641 -0.275741 -0.641018  14.597718\n",
       " 591   0.005335 -0.396899 -0.011026 -0.107748  0.260796   3.888600\n",
       " 322  -1.144475  1.144705 -0.091210  0.855956 -0.174387   3.907677\n",
       " 138  -0.410166  0.054483  0.648448 -1.656817  0.127909  -5.084823\n",
       " ...        ...       ...       ...       ...       ...        ...\n",
       " 1676 -0.584667  0.833516 -1.151453  0.734843  0.573349  -2.602968\n",
       " 129   0.609697  1.524423  1.152034  0.195733 -0.133834   7.758787\n",
       " 900   2.200780  0.421673 -1.870648  0.146652 -0.682617   1.116112\n",
       " 826  -0.226725 -1.051592  0.505996 -0.064839 -1.579572  14.801998\n",
       " 1600  1.363118  0.508119  0.710688  1.283337 -0.607225  19.425373\n",
       " \n",
       " [228 rows x 6 columns]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = reg_data.split_to_batches(data=train, number_of_batches=7)\n",
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.60329413e-01, -2.02226019e+00, -3.85206282e-01,\n",
       "        -7.56873608e-01, -1.21367514e+00],\n",
       "       [-1.17203116e+00, -5.61344862e-01,  2.40600514e+00,\n",
       "        -1.83322656e+00,  6.10662937e-01],\n",
       "       [ 9.10888374e-01, -8.19529295e-01, -8.84485841e-01,\n",
       "        -3.74983251e-01, -3.03448737e-01],\n",
       "       ...,\n",
       "       [ 6.40358746e-01,  4.86048996e-01, -5.41169584e-01,\n",
       "        -9.40911829e-01,  1.87421771e-04],\n",
       "       [-1.55017805e+00,  3.77594799e-01,  9.66798365e-01,\n",
       "         4.97803122e-01, -2.64029145e-01],\n",
       "       [ 3.21731776e-01, -1.81738830e+00,  6.96517348e-01,\n",
       "        -9.37991381e-01, -8.51059794e-01]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[0]['input'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=114.73258>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LinearRegression(dimensionality=5)\n",
    "m.loss(m(batches[0]['input'].to_numpy()),batches[0]['output'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=114.69507>,\n",
       " [<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       "  array([[ -3.1385741],\n",
       "         [  5.6349955],\n",
       "         [ -8.081214 ],\n",
       "         [-15.644523 ],\n",
       "         [  3.6313984]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-9.69441], dtype=float32)>])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    loss = m.loss(m(batches[0]['input'].to_numpy()), batches[0]['output'].to_numpy())\n",
    "\n",
    "grads = tape.gradient(loss, m.trainable_variables)\n",
    "loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21225202, -0.01655633],\n",
       "       [-1.7237953 , -0.19700338],\n",
       "       [-0.14077929, -1.2567658 ],\n",
       "       ...,\n",
       "       [-0.4010439 , -0.6913797 ],\n",
       "       [ 0.23575255, -2.1456401 ],\n",
       "       [ 1.6914388 , -0.15264705]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.830437 ],\n",
       "       [ 1.4253321],\n",
       "       [ 8.188075 ],\n",
       "       ...,\n",
       "       [ 5.7421474],\n",
       "       [11.965922 ],\n",
       "       [ 8.104585 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticRegressionData(DataModule):\n",
    "    \"\"\"Defined in :numref:`sec_synthetic-regression-data`\"\"\"\n",
    "    def __init__(self, w, b, noise_value=0.01, num_train=1000, num_val=1000,\n",
    "                 batch_size=32):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.noise_value = noise_value\n",
    "        self.num_train = num_train\n",
    "        self.num_val = num_val\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.X, self.y = self._create_data()\n",
    "\n",
    "    def _create_data(self):\n",
    "        n = self.num_train + self.num_val\n",
    "        noise = tf.random.normal((n, 1)) * self.noise_value\n",
    "        X = tf.random.normal((n, self.w.shape[0]))\n",
    "        y = tf.matmul(X, tf.reshape(self.w, (-1, 1))) + self.b + noise\n",
    "        return X, y\n",
    "\n",
    "    def get_dataloader(self, train):\n",
    "        \"\"\"Defined in :numref:`sec_synthetic-regression-data`\"\"\"\n",
    "        i = slice(0, self.num_train) if train else slice(self.num_train, None)\n",
    "        return self.get_tensorloader((self.X, self.y), train, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \"\"\"Defined in :numref:`subsec_oo-design-models`\"\"\"\n",
    "    def __init__(self, max_epochs, gradient_clip_val=0):\n",
    "        self.max_epochs = max_epochs\n",
    "        self.gradient_clip_val = gradient_clip_val\n",
    "\n",
    "        # self.optim = tf.keras.optimizers.SGD(0.03)\n",
    "\n",
    "    def prepare_data(self, data: DataModule):\n",
    "        self.train_dataloader = data.train_dataloader()\n",
    "        self.val_dataloader = data.val_dataloader()\n",
    "        self.num_train_batches = len(self.train_dataloader)\n",
    "        self.num_val_batches = (len(self.val_dataloader)\n",
    "                                if self.val_dataloader is not None else 0)\n",
    "\n",
    "    def prepare_model(self, model: MLArchitecture):\n",
    "        self.model = model\n",
    "\n",
    "    def prepare_optimizer(self, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def fit(self, model: MLArchitecture, data: DataModule, optimizer):\n",
    "        self.prepare_data(data)\n",
    "        self.prepare_model(model)\n",
    "        self.prepare_optimizer(optimizer)\n",
    "        # self.optim = model.configure_optimizers()\n",
    "        self.epoch = 0\n",
    "        self.train_batch_idx = 0\n",
    "        self.val_batch_idx = 0\n",
    "        for self.epoch in range(self.max_epochs):\n",
    "            self.fit_epoch()\n",
    "\n",
    "    def extract_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def prepare_batch(self, batch):\n",
    "        \"\"\"Defined in :numref:`sec_linear_scratch`\"\"\"\n",
    "        return batch\n",
    "\n",
    "    def evaluate(self, X, Y_true):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.model.loss(self.model(X), Y_true)\n",
    "\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        return loss, grads\n",
    "\n",
    "\n",
    "\n",
    "    def fit_epoch(self):\n",
    "        \"\"\"Defined in :numref:`sec_linear_scratch`\"\"\"\n",
    "        # self.model.training = True\n",
    "        for batch in self.train_dataloader:\n",
    "            \n",
    "            loss, grads = self.evaluate(*batch[:-1],batch[-1])\n",
    "\n",
    "            # Optimization update\n",
    "            w = self.model.get_model_weights()\n",
    "            update = w - (0.03 * get_flat_array_from_list_of_arrays(grads))\n",
    "            self.model.set_model_weights(update)\n",
    "\n",
    "            self.train_batch_idx += 1\n",
    "\n",
    "\n",
    "        if self.val_dataloader is None:\n",
    "            return\n",
    "\n",
    "            \n",
    "        # self.model.training = False\n",
    "        for batch in self.val_dataloader:\n",
    "            self.model.validation_step(self.prepare_batch(batch))\n",
    "            self.val_batch_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0008564],\n",
       "       [-3.3875527],\n",
       "       [ 4.987299 ],\n",
       "       [ 4.187114 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 3\n",
    "seed = 42\n",
    "data = SyntheticRegressionData(w=tf.constant([2, -3.4, 5.]), b=4.2)\n",
    "trainer = Trainer(max_epochs=3)\n",
    "\n",
    "model = LinearRegression(dimensionality=dim)\n",
    "\n",
    "design = f3dasm.make_nd_continuous_design(bounds=np.tile([-1.,1.], (dim+1, 1)), dimensionality=dim+1)\n",
    "\n",
    "sampler = f3dasm.sampling.LatinHypercube(design=design,seed=seed)\n",
    "N = sampler.get_samples(1)\n",
    "w = N.get_input_data().to_numpy().ravel()\n",
    "\n",
    "model.set_model_weights(w)\n",
    "\n",
    "\n",
    "trainer.fit(model=model, data=data, optimizer=tf.keras.optimizers.SGD(0.03))\n",
    "\n",
    "model2 = trainer.extract_model()\n",
    "model2.get_model_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0006688890280202031 \n",
      "\n",
      " gradient: [[-0.0008425 ]\n",
      " [ 0.02829554]\n",
      " [-0.02690743]\n",
      " [-0.01597123]] \n",
      "\n",
      " gradient_orig: [<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
      "array([[-0.0008425 ],\n",
      "       [ 0.02829554],\n",
      "       [-0.02690743]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.01597123], dtype=float32)>]\n",
      "[array([[ 2.0008564],\n",
      "       [-3.3875527],\n",
      "       [ 4.987299 ]], dtype=float32), array([4.187114], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for batch in data.train_dataloader():\n",
    "    loss, gradient = trainer.evaluate(*batch[:-1],batch[-1])\n",
    "\n",
    "    gr = get_flat_array_from_list_of_arrays(gradient)\n",
    "    print(f\"loss: {loss} \\n\\n gradient: {gr} \\n\\n gradient_orig: {gradient}\")\n",
    "    break\n",
    "\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([[ 2.0008817],\n",
       "               [-3.3875275],\n",
       "               [ 4.987324 ]], dtype=float32),\n",
       "        array([4.187139], dtype=float32)],\n",
       "       [array([[ 2.0000076],\n",
       "               [-3.3884015],\n",
       "               [ 4.98645  ]], dtype=float32),\n",
       "        array([4.186265], dtype=float32)],\n",
       "       [array([[ 2.0016637],\n",
       "               [-3.3867455],\n",
       "               [ 4.9881063]], dtype=float32),\n",
       "        array([4.187921], dtype=float32)],\n",
       "       [array([[ 2.0013356],\n",
       "               [-3.3870735],\n",
       "               [ 4.987778 ]], dtype=float32),\n",
       "        array([4.187593], dtype=float32)]], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights() - (0.03 * gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.0008425 ],\n",
       "        [ 0.02829554],\n",
       "        [-0.02690743]], dtype=float32),\n",
       " array([[-0.01597123]], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reshaped_array_from_list_of_arrays(gr, gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(3, 1) dtype=float32, numpy=\n",
       " array([[ 2.0008564],\n",
       "        [-3.3875527],\n",
       "        [ 4.987299 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([4.187114], dtype=float32)>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.extract_model().weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.extract_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.0008564],\n",
       "        [-3.3875527],\n",
       "        [ 4.987299 ]], dtype=float32),\n",
       " array([4.187114], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.25091976,  0.90142861,  0.46398788,  0.19731697])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "design = f3dasm.make_nd_continuous_design(bounds=np.tile([-1.,1.], (dim+1, 1)), dimensionality=dim+1)\n",
    "\n",
    "sampler = f3dasm.sampling.LatinHypercube(design=design,seed=seed)\n",
    "N = sampler.get_samples(1)\n",
    "w = N.get_input_data().to_numpy().ravel()\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [a.shape for a in model.model.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = get_reshaped_array_from_list_of_arrays(w, model.model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3307102578.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[25], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    weights.\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.get_weights().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('f3dasm_env3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03276761335d5ee93b82dc97db1addd68180a543fb0cacb8af76ec058b1972b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
